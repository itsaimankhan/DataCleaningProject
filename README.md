# Data Cleaning Project 

This project demonstrates essential data cleaning and preprocessing techniques using the Titanic dataset from Kaggle. It showcases how to handle missing data, engineer features, and prepare a dataset for further analysis or machine learning tasks.

---

## ğŸ“ Files Included

- `train.csv` â€“ Original dataset (downloaded from Kaggle)  
- `data_cleaned.csv` â€“ Cleaned and ready-to-use dataset  
- `data_cleaning.ipynb` â€“ Jupyter Notebook containing the full cleaning process  
- `README.md` â€“ This project overview and documentation  

---

## ğŸ›  Tools Used

- Python  
- Pandas  
- NumPy  
- Seaborn  
- Matplotlib  

---

## ğŸ” Key Steps Performed

- âœ… Handled missing values in `Age` and `Embarked`  
- âœ… Dropped highly incomplete column `Cabin`  
- âœ… Encoded categorical variables like `Sex` and `Embarked`  
- âœ… Engineered a new feature: `FamilySize`  
- âœ… Visualized correlations using a heatmap  
- âœ… Exported a clean, modeling-ready dataset  

---

## ğŸ“Š Dataset Source

[Kaggle: Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/data)

---

## âœ¨ Outcome

This project highlights core data wrangling skills crucial for data science roles. The final cleaned dataset is ready for exploratory analysis, machine learning model training, or integration into dashboards and reporting tools.

---
